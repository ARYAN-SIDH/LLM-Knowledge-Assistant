# AI Knowledge Assistant using LLMs

## ğŸš€ Overview
An AI-powered knowledge assistant that uses a fine-tuned Large Language Model (LLM) to provide context-aware answers and summaries through a React + Flask web app.

## âœ¨ Features
- Fine-tuned GPT-J or LLaMA for niche domain Q&A
- React frontend with chat-like UI
- Flask backend serving the model
- Prompt engineering & ranking
- Caching for speed

## ğŸ“‚ Structure
- `/frontend` â€” React app
- `/backend` â€” Flask API, model scripts
- `/model` â€” Fine-tuning & prompt files
- `/data` â€” Example training data

## ğŸ§° Tech Stack
- LLM: GPT-J, LLaMA (via Hugging Face)
- Frontend: React, Axios
- Backend: Flask, Transformers, Torch

## âš¡ï¸ Run Locally
```bash
git clone https://github.com/YOUR_USERNAME/ai-knowledge-assistant-llm.git
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python app.py

# In another terminal
cd ../frontend
npm install
npm start
```
Open [http://localhost:3000](http://localhost:3000)

## ğŸ¤– Demo
Add screenshots or a demo GIF here.

## ğŸ“š Learnings
- Fine-tuning LLMs
- Prompt design
- Caching & latency trade-offs
- End-to-end deployment

## ğŸ“œ License
MIT License.
